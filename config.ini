# Configuration file for default B-SOiD values. Alter values as needed.
# If you decide to change a key name, make sure that the string name reference in bsoid/config.py is also changed.

[PATH]
# DLC_PROJECT_PATH (NEWLY OPTIONAL): required. An absolute path to a folder. Legacy variable that  # TODO
#   seems to be a pivot point for operations. BASE_PATH will be reworked in the future.
    # DLC_PROJECT_PATH = C:\Users\killian\projects\OST-with-DLC\EPM_DLC_BSOID-Tim-2020-08-25
    # DLC_PROJECT_PATH = /home/aaron/Documents/OST-with-DLC/EPM_DLC_BSOID-Tim-2020-08-25
DLC_PROJECT_PATH =

# TRAIN_DATA_FOLDER_PATH (NEWLY OPTIONAL): used to be part of legacy implementation where data was implicitly pulled.  # TODO
    # e.g.: TRAIN_DATA_FOLDER_PATH = C:\Users\killian\projects\OST-with-DLC\bsoid_train_videos
TRAIN_DATA_FOLDER_PATH =
# PREDICT_DATA_FOLDER_PATH (NEWLY OPTIONAL):
    # e.g.: PREDICT_DATA_FOLDER_PATH = C:\Users\killian\projects\OST-with-DLC\bsoid_test_videos
PREDICT_DATA_FOLDER_PATH =

# OUTPUT_PATH (optional, absolute path): Leave blank to use default path within
#   B-SOID project directory (BSOID/output). Otherwise, specify an absolute path to a folder
OUTPUT_PATH =
# VIDEOS_OUTPUT (optional, str): Full directory path. Optional. If not specified, it will go into the BSOID/output
VIDEOS_OUTPUT_PATH =
# ALTERNATE_OUTPUT_PATH_FOR_ANNOTATED_FRAMES (optional, absolute path): Leave blank to
#   use BSOID/output/frames as default output path, otherwise include a full path as an alternative.
ALTERNATE_OUTPUT_PATH_FOR_ANNOTATED_FRAMES =


# C:\Users\killian\projects\OST-with-DLC\GUI_projects\OST-DLC-projects\pwd-may11-2020-john-howland-2020-05-11
[APP]
# OUTPUT_MODEL_NAME (required): Name of model to be used when saving information. TODO: deprecate? Pipeline favoured over Model
OUTPUT_MODEL_NAME = TestModel
# PIPELINE_NAME (required):
PIPELINE_NAME = TestPipeline
# VIDEO_TO_LABEL_PATH (required, file path): If the path is RELATIVE, it will be relative to DLC_PROJECT_PATH  # TODO: move this to PATH section
# # VIDEO_TO_LABEL_PATH = C:\Users\killian\projects\OST-with-DLC\EPM_DLC_BSOID-Tim-2020-08-25\sample_train_data_folder\Video1.mp4
VIDEO_TO_LABEL_PATH =
# VIDEO_FRAME_RATE (required, int):
VIDEO_FRAME_RATE = 30
# COMPILE_CSVS_FOR_TRAINING (required, int):  COMP=0 is one classifier/CSV file; COMP=1 is one classifier for all CSV files
COMPILE_CSVS_FOR_TRAINING = 1
# PLOT_GRAPHS (required, bool): Change to False if you don't want plots brought up. It'll still save the output CSVs.
PLOT_GRAPHS = False
# SAVE_GRAPHS_TO_FILE (required, bool):
SAVE_GRAPHS_TO_FILE = False
# GENERATE_VIDEOS (required, bool): if this is true, make sure direct to the video below AND that you created the two specified folders!
GENERATE_VIDEOS = True
# FRAMES_OUTPUT_FORMAT (str):
FRAMES_OUTPUT_FORMAT = png
# DEFAULT_SAVED_GRAPH_FILE_FORMAT (str): Some valid file extensions: svg, jpg . For now, you must not pick 'png'. TODO: elaborate on below var desc.
DEFAULT_SAVED_GRAPH_FILE_FORMAT = jpg
# PERCENT_FRAMES_TO_LABEL (required, float): the percent of frames in VIDEO to label and output to FRAMES output path  # TODO: evaluate how it works, and if to keep, in new model structure
PERCENT_FRAMES_TO_LABEL = 0.5
# OUTPUT_VIDEO_FPS (optional, int): If left blank, BSOID will match the input video FPS on output taking PERCENT_FRAMES_TO_LABEL into account TODO: explain better
OUTPUT_VIDEO_FPS =
# N_JOBS (required, int): Number of cores to use in multiprocessing steps. This value must be 1 or greater.
N_JOBS = 4
# FILE_IDENTIFICATION_ORDER_LEGACY (required, int): TODO: low/med: deprecate
FILE_IDENTIFICATION_ORDER_LEGACY = 0

[STREAMLIT]
# default_pipeline_location (str, optional): specify the location  # TODO: elaborate. Useful!
default_pipeline_location =

;[VIDEO]
;stuff =

[DLC_FEATURES]
# Modify the below values to reflect the name of the body parts used in DLC which will then be parsed in B-SOiD.
# To add more features: TODO: med: explain
SNOUT/HEAD = Snout/Head
LEFT_SHOULDER/FOREPAW = Forepaw/Shoulder1
RIGHT_SHOULDER/FOREPAW = Forepaw/Shoulder2
LEFT_HIP/HINDPAW = Hindpaw/Hip1
RIGHT_HIP/HINDPAW = Hindpaw/Hip2
TAILBASE = Tailbase
NOSETIP = NoseTip
FOREPAW_LEFT = ForepawLeft
FOREPAW_RIGHT = ForepawRight
HINDPAW_LEFT = HindpawLeft
HINDPAW_RIGHT = HindpawRight


[MODEL]
# RANDOM_STATE (required, int): Leave random_state value blank for using an actually random seed value
RANDOM_STATE = 42
# HOLDOUT_TEST_PCT (required, float):
HOLDOUT_TEST_PCT = 0.35
# CROSS_VALIDATION_K (required, int):
CROSS_VALIDATION_K = 5
# CROSS_VALIDATION_N_JOBS (required, int): Number of cores used for k-fold cross validation
#                                          (set to -1 to use all cores, -2 to use all cores but one)
CROSS_VALIDATION_N_JOBS = -2


[LOGGING]
### Name, format, and create log levels for the logger
### Valid log levels are limited to: CRITICAL, FATAL, ERROR, WARN, WARNING, INFO, DEBUG, NOTSET
# LOGGER_NAME (required, str):
DEFAULT_LOGGER_NAME = default_logger
# LOG_FILE_NAME (required, str):
LOG_FILE_NAME = default.log
# LOG_FORMAT (required, str):
LOG_FORMAT = %(asctime)s - %(name)s - %(levelname)-8s - %(message)s
# STREAM_LOG_LEVEL (required, str): (Debugging: DEBUG) TODO: low: elaborate
STREAM_LOG_LEVEL = DEBUG
# FILE_LOG_LEVEL (required):
FILE_LOG_LEVEL = WARNING
# LOG_FILE_FOLDER_PATH (optional, absolute path): Leave LOG_FILE_FOLDER_PATH blank to use the default pathing. Otherwise,
#    fill value with an ABSOLUTE to the folder where log will be kept
LOG_FILE_FOLDER_PATH =


[TESTING]
# DEFAULT_TEST_FILE (required, file name): Must reside in: B-SOiD/tests/test_data  TODO: low: elaborate
DEFAULT_CSV_TEST_FILE = RowsDeleted_FullSample_Video1DLC_resnet50_EPM_DLC_BSOIDAug25shuffle1_495000.csv
# DEFAULT_H5_TEST_FILE (required, file name): must reside in B-SOiD/tests/test_data  TODO: low: elaborate
DEFAULT_H5_TEST_FILE = RowsDeleted_FullSample_Video1DLC_resnet50_EPM_DLC_BSOIDAug25shuffle1_495000.h5
# max_rows_to_read_in_from_csv (optional, int): change this value to set the maximum  # TODO: deprecate since old and new way of reading max lines is different?
MAX_ROWS_TO_READ_IN_FROM_CSV = 100_000_000_000


[VIDEO]
DEFAULT_FONT_SCALE = 1
DEFAULT_TEXT_BGR = (255, 255, 255)
DEFAULT_TEXT_BACKGROUND_BGR = (0, 0, 0)


########################################################################################################################
### Classifier parameters ###

[EM/GMM]
# n_components (required, int): n clusters (set to 30 after debugging)  TODO: med: re-read paper and find optimal n_components
n_components = 16
# covariance_type: # Must be one of: {full, tied, diag, spherical} (Original author's note: "t-SNE structure means nothing") (see the following link for more information: https://scikit-learn.org/stable/auto_examples/mixture/plot_gmm_covariances.html)
covariance_type = full
# tol: (set to 0.001 after debugging)  TODO: Elaborate
tol = 0.001
# reg_covar: (set to 1e-06 after debugging)
reg_covar = 1e-06
# init_params (required, str): Initialization parameters. Must be one of {random, kmeans}
init_params = kmeans
# max_iter (required, int): TODO: Elaborate
max_iter = 100
# n_init (required, int): (Original author's comment: 20 iterations to escape poor initialization)  TODO: elaborate
n_init = 20
# verbose (required, int): Enable verbose output. If 1 then it prints the current initialization and each iteration step. If greater than 1 then it prints also the log probability and the time needed for each step.
verbose = 0
# verbose_interval (optional, int): How often the verbose output goes to stdout
verbose_interval = 50

[HDBSCAN]
# min_samples (required, int): (authors' note: small number)
min_samples = 10


[MLP]
# activation (required, str): logistics appears to outperform tanh and relu
activation = logistic
# hidden_layer_size (required, tuple of integers): **IMPORTANT NOTE**: hidden_layer_sizes is a
#   special variable that is evaluated exactly as it is written. Thus, if it is
#   written as '(100, 10)' (without the single quotes), it will be interpreted as a tuple of integers.
hidden_layer_sizes = (100, 10)
# solver (required, str):
solver = adam
# learning_rate (required, str):
learning_rate = constant
# learning_rate_init (required, float):
learning_rate_init = 0.001
# alpha (required, float): (Original note: regularization default is better than higher values.)
alpha = 0.0001
# max_iter: (original value is 1000)
max_iter = 100
# early_stopping (required, bool):
early_stopping = False
# verbose (required, int): set verbose=1 for tuning feedforward neural network
verbose = 0


[SVM]
# C (required, float):
C = 10
# gamma (required, float):
gamma = 0.5
# probability (required, bool):
probability = True
# verbose (required, int): (Change back to 0 when done debugging)
verbose = 0
# n_jobs (required, int): Number of cores to use in training model.
#    n_jobs = -1 means all cores being used, set to -2 for all cores but one.
n_jobs = -2


[UMAP]
# n_neighbors (required, int):
n_neighbors = 100
# n_components (required, int): TODO
n_components = 3
# min_dist: small value
min_dist = 0.0


[TSNE]
# early_exaggeration (float, required):
early_exaggeration = 16
# n_components: (original author's note: 3 is good, 2 will not create unique pockets, 4 will screw GMM up (curse of dimensionality))
n_components = 3
# n_iter (required, int): 250 is the minimum value...previous n_iter was set to 1,000
n_iter = 1_000
# n_jobs: n_jobs=-1: all cores being used, set to -2 for all cores but one.
n_jobs = -2
# theta (float, required):
theta = 0.5
# verbose (required, int): (original note: verbose=2 shows check points)
verbose = 0










