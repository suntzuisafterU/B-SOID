# Configuration file for B-SOiD use. Alter values as needed.
# If you decide to change a key name, make sure that the string name reference in bsoid/config.py is also changed.

[PATH]
# DLC_PROJECT_PATH (required): required. An absolute path to a folder. Legacy variable that seems to be a pivot point for operations. BASE_PATH will be reworked in the future.
# DLC_PROJECT_PATH = C:\Users\killian\projects\OST-with-DLC\GUI_projects\OST-DLC-projects\pwd-may11-2020-john-howland-2020-05-11
DLC_PROJECT_PATH = C:\Users\killian\projects\OST-with-DLC\GUI_projects\EPM-DLC-projects
# DLC_PROJECT_PATH = /home/aaron/Documents/OST-with-DLC/GUI_projects/OST-DLC-projects/pwd-may11-2020-john-howland-2020-05-11

# OUTPUT_PATH (optional): leave blank to use default path within B-SOID project directory, otherwise specify an absolute path to a folder
OUTPUT_PATH =
# OST_BASE_PROJECT_PATH (required):
OST_BASE_PROJECT_PATH = C:\Users\killian\projects\OST-with-DLC\GUI_projects
# OST_BASE_PROJECT_PATH = /home/aaron/Documents/OST-with-DLC'

# OST_OUTPUT_PATH: required
OST_OUTPUT_PATH =
# ALTERNATE_OUTPUT_PATH_FOR_ANNOTATED_FRAMES: completely optional. Leave blank to use BSOID/output/frames as default, otherwise include a FULL path as a value.
ALTERNATE_OUTPUT_PATH_FOR_ANNOTATED_FRAMES =


# C:\Users\killian\projects\OST-with-DLC\GUI_projects\OST-DLC-projects\pwd-may11-2020-john-howland-2020-05-11
[APP]
# OUTPUT_MODEL_NAME (required): Name of model to be used when saving information
OUTPUT_MODEL_NAME = DEFAULT_MODEL_NAME__CHANGE_ME
# VIDEO_TO_LABEL_PATH (required, file path): If the path is RELATIVE, it will be relative to ____ (BASEPATH? TODO!), otherwise it will be treated as an absolute.
VIDEO_TO_LABEL_PATH = C:\Users\killian\projects\OST-with-DLC\GUI_projects\labelled_videos\002_ratA_inc2_above.mp4
# VIDEO_FRAME_RATE (required, int):
VIDEO_FRAME_RATE = 60
# COMPILE_CSVS_FOR_TRAINING (required, int):  COMP=0 is one classifier/CSV file; COMP=1 is one classifier for all CSV files
COMPILE_CSVS_FOR_TRAINING = 1
# FILE_IDENTIFICATION_ORDER_LEGACY (required, int): What number would be video be in terms of prediction order? (0=file 1/folder1, 1=file2/folder 1, etc.)
FILE_IDENTIFICATION_ORDER_LEGACY = 0

# PLOT_GRAPHS (required, bool): Change to False if you don't want plots brought up. It'll still save the output CSVs.
PLOT_GRAPHS = True
# SAVE_GRAPHS_TO_FILE (required, bool):
SAVE_GRAPHS_TO_FILE = True
# GENERATE_VIDEOS: if this is true, make sure direct to the video below AND that you created the two specified folders!
GENERATE_VIDEOS = True
# ID (required, int): should be deprecated in the future. Legacy option.
ID = 0

# PLOT_TRAINING: DEPRECATED


[MODEL]
# RANDOM_STATE (required, int): Leave random_state value blank for using an actually random seed value
RANDOM_STATE = 42
# HOLDOUT_TEST_PCT (required, float):
HOLDOUT_TEST_PCT = 0.20
# CROSS_VALIDATION_K (required, int):
CROSS_VALIDATION_K = 10
# CROSS_VALIDATION_N_JOBS (required, int):  (set to -1 to use all cores, -2 to use all cores but one)
CROSS_VALIDATION_N_JOBS = -2


[LOGGING]
### Name, format, and create log levels for the logger
### Valid log levels are limited to: CRITICAL, FATAL, ERROR, WARN, WARNING, INFO, DEBUG, NOTSET
# LOGGER_NAME (required):
DEFAULT_LOGGER_NAME = default_logger
# LOG_FILE_NAME (required):
LOG_FILE_NAME = default.log
# LOG_FORMAT (required):
LOG_FORMAT = %(asctime)s - %(name)s - %(levelname)-8s - %(message)s
# STREAM_LOG_LEVEL (required):
STREAM_LOG_LEVEL = DEBUG
# FILE_LOG_LEVEL (required):
FILE_LOG_LEVEL = WARNING
# LOG_FILE_FOLDER_PATH (optional, absolute path): Leave LOG_FILE_FOLDER_PATH blank to use the default pathing. Otherwise,
#    fill value with an ABSOLUTE to the folder where log will be kept
LOG_FILE_FOLDER_PATH =


######################################
### Classifier-specific parameters ###

[EM/GMM]
# n_components (required, int):
n_components = 30
# covariance_type: # t-SNE structure means nothing.
covariance_type = full
# tol:
tol = 0.001
# reg_covar:
reg_covar = 1e-06
# init_params: random initialization
init_params = random
# max_iter (required, int):
max_iter = 100
# n_init: 20 iterations to escape poor initialization
n_init = 20
# verbose: set this to 0 if you don't want to show progress for em-gmm.
verbose = 1


[HDBSCAN]
min_samples = 10


[MLP]
# activation: logistics appears to outperform tanh and relu
activation = logistic
# hidden_layer_sizes: **IMPORTANT NOTE**: hidden_layer_sizes is special variable that is evaluated exactly as
#   it is written. Thus, if it is written as '(100, 10)', it will be interpreted as a tuple.
hidden_layer_sizes = (100, 10)
# solver:
solver = adam
# learning_rate:
learning_rate = constant
# learning_rate_init:
learning_rate_init = 0.001
# alpha: # regularization default is better than higher values.
alpha = 0.0001
# max_iter:
max_iter = 1000
# early_stopping:
early_stopping = False
# verbose: set verbose=1 for tuning feedforward neural network
verbose = 0


[SVM]
C = 10
gamma = 0.5
probability = True
random_state = 0
verbose = 0
# n_jobs: n_jobs=-1: all cores being used, set to -2 for all cores but one.
n_jobs = -2

[UMAP]
n_components = 3
# min_dist: small value
min_dist = 0.0

[TSNE]
# n_components: 3 is good, 2 will not create unique pockets, 4 will screw GMM up (curse of dimensionality)
n_components = 3
# n_jobs: n_jobs=-1: all cores being used, set to -2 for all cores but one.
n_jobs = -2
# verbose: verbose=2 shows check points
verbose = 1

