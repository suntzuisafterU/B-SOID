# Configuration file for B-SOiD use. Alter values as needed.
# If you decide to change a key name, make sure that the string name reference in bsoid/config.py is also changed.

[PATH]
# DLC_PROJECT_PATH (required): required. An absolute path to a folder. Legacy variable that
#   seems to be a pivot point for operations. BASE_PATH will be reworked in the future.
# DLC_PROJECT_PATH = C:\Users\killian\projects\OST-with-DLC\GUI_projects\EPM-DLC-projects
# DLC_PROJECT_PATH = C:\Users\killian\projects\OST-with-DLC\EPM_DLC_BSOID-Tim-2020-08-25
# DLC_PROJECT_PATH = /home/aaron/Documents/OST-with-DLC/EPM_DLC_BSOID-Tim-2020-08-25
DLC_PROJECT_PATH =

# TRAIN_DATA_FOLDER_PATH:
# TRAIN_DATA_FOLDER_PATH = C:\Users\killian\projects\OST-with-DLC\bsoid_train_videos
TRAIN_DATA_FOLDER_PATH =
# PREDICT_DATA_FOLDER_PATH
# PREDICT_DATA_FOLDER_PATH = C:\Users\killian\projects\OST-with-DLC\bsoid_test_videos
PREDICT_DATA_FOLDER_PATH =

# OUTPUT_PATH (optional, absolute path): Leave blank to use default path within
#   B-SOID project directory. Otherwise, specify an absolute path to a folder
OUTPUT_PATH =
# VIDEOS_OUTPUT (optional, str): Full path. TODO
VIDEOS_OUTPUT_PATH =
# ALTERNATE_OUTPUT_PATH_FOR_ANNOTATED_FRAMES (optional, absolute path): Leave blank to
#   use BSOID/output/frames as default output path, otherwise include a full path as an alternative.
ALTERNATE_OUTPUT_PATH_FOR_ANNOTATED_FRAMES =

# C:\Users\killian\projects\OST-with-DLC\GUI_projects\OST-DLC-projects\pwd-may11-2020-john-howland-2020-05-11
[APP]
# OUTPUT_MODEL_NAME (required): Name of model to be used when saving information
OUTPUT_MODEL_NAME = TestModel
# PIPELINE_NAME (required):
PIPELINE_NAME = TestPipeline
# VIDEO_TO_LABEL_PATH (required, file path): If the path is RELATIVE, it will be relative to DLC_PROJECT_PATH  # TODO: move this to PATH section
# # VIDEO_TO_LABEL_PATH = C:\Users\killian\projects\OST-with-DLC\EPM_DLC_BSOID-Tim-2020-08-25\sample_train_data_folder\Video1.mp4
VIDEO_TO_LABEL_PATH =
# VIDEO_FRAME_RATE (required, int):
VIDEO_FRAME_RATE = 30
# COMPILE_CSVS_FOR_TRAINING (required, int):  COMP=0 is one classifier/CSV file; COMP=1 is one classifier for all CSV files
COMPILE_CSVS_FOR_TRAINING = 1
# PLOT_GRAPHS (required, bool): Change to False if you don't want plots brought up. It'll still save the output CSVs.
PLOT_GRAPHS = False
# SAVE_GRAPHS_TO_FILE (required, bool):
SAVE_GRAPHS_TO_FILE = False
# GENERATE_VIDEOS (required, bool): if this is true, make sure direct to the video below AND that you created the two specified folders!
GENERATE_VIDEOS = True
# FRAMES_OUTPUT_FORMAT (str):
FRAMES_OUTPUT_FORMAT = png
# DEFAULT_SAVED_GRAPH_FILE_FORMAT (str): Some valid file extensions: svg, jpg . For now, you must not pick 'png'. TODO: elaborate on below var desc.
DEFAULT_SAVED_GRAPH_FILE_FORMAT = jpg
# PERCENT_FRAMES_TO_LABEL (required, float): the percent of frames in VIDEO to label and output to FRAMES output path
PERCENT_FRAMES_TO_LABEL = 0.5
# OUTPUT_VIDEO_FPS (optional, int): If left blank, BSOID will match the input video FPS on output taking PERCENT_FRAMES_TO_LABEL into account TODO: explain better
OUTPUT_VIDEO_FPS =
# N_JOBS (required, int): Number of cores to use in multiprocessing steps
N_JOBS = 4
# FILE_IDENTIFICATION_ORDER_LEGACY (required, int): TODO: deprecate
FILE_IDENTIFICATION_ORDER_LEGACY = 0

[VIDEO]
stuff =

[DLC_FEATURES]
# Modify the below values to reflect the name of the body parts used in DLC which will then be parsed in B-SOiD.
# To add more features: TODO: explain
# HEAD = Head
SNOUT/HEAD = Snout/Head
LEFT_SHOULDER/FOREPAW = Forepaw/Shoulder1
RIGHT_SHOULDER/FOREPAW = Forepaw/Shoulder2
LEFT_HIP/HINDPAW = Hindpaw/Hip1
RIGHT_HIP/HINDPAW = Hindpaw/Hip2
TAILBASE = Tailbase
NOSETIP =
FOREPAW_LEFT =
FOREPAW_RIGHT =
HINDPAW_LEFT =
HINDPAW_RIGHT =


[MODEL]
# RANDOM_STATE (required, int): Leave random_state value blank for using an actually random seed value
RANDOM_STATE = 42
# HOLDOUT_TEST_PCT (required, float):
HOLDOUT_TEST_PCT = 0.20
# CROSS_VALIDATION_K (required, int):
CROSS_VALIDATION_K = 10
# CROSS_VALIDATION_N_JOBS (required, int):  (set to -1 to use all cores, -2 to use all cores but one)
CROSS_VALIDATION_N_JOBS = -2


[LOGGING]
### Name, format, and create log levels for the logger
### Valid log levels are limited to: CRITICAL, FATAL, ERROR, WARN, WARNING, INFO, DEBUG, NOTSET
# LOGGER_NAME (required, str):
DEFAULT_LOGGER_NAME = default_logger
# LOG_FILE_NAME (required, str):
LOG_FILE_NAME = default.log
# LOG_FORMAT (required, str):
LOG_FORMAT = %(asctime)s - %(name)s - %(levelname)-8s - %(message)s
# STREAM_LOG_LEVEL (required, str): (Debugging: DEBUG) TODO
STREAM_LOG_LEVEL = DEBUG
# FILE_LOG_LEVEL (required):
FILE_LOG_LEVEL = WARNING
# LOG_FILE_FOLDER_PATH (optional, absolute path): Leave LOG_FILE_FOLDER_PATH blank to use the default pathing. Otherwise,
#    fill value with an ABSOLUTE to the folder where log will be kept
LOG_FILE_FOLDER_PATH =


[TESTING]
# DEFAULT_TEST_FILE: Must reside in: B-SOiD/tests/test_data  TODO: low: elaborate
DEFAULT_TEST_FILE = RowsDeleted_FullSample_Video1DLC_resnet50_EPM_DLC_BSOIDAug25shuffle1_495000.csv
# max_rows_to_read_in_from_csv (optional, int): change this value to set the maximum
MAX_ROWS_TO_READ_IN_FROM_CSV = 100_000_000

########################################################################################################################
### Classifier-specific parameters ###

[EM/GMM]
# n_components (required, int): (set to 30 after debugging)
n_components = 10
# covariance_type: # t-SNE structure means nothing.
covariance_type = full
# tol: (set to 0.001 after debugging)
tol = 3
# reg_covar:
reg_covar = 1e-06
# init_params (required): random initialization
init_params = random
# max_iter (required, int): (standard value is 100. Change back to 100 after debugging.)
max_iter = 10
# n_init: 20 iterations to escape poor initialization
n_init = 20
# verbose: set this to 0 if you don't want to show progress for em-gmm.
verbose = 0


[HDBSCAN]
min_samples = 10


[MLP]
# activation (required, str): logistics appears to outperform tanh and relu
activation = logistic
# hidden_layer_size (required, tuple of integers): **IMPORTANT NOTE**: hidden_layer_sizes is a
#   special variable that is evaluated exactly as it is written. Thus, if it is
#   written as '(100, 10)' (without the single quotes), it will be interpreted as a tuple of integers.
hidden_layer_sizes = (100, 10)
# solver (required, str):
solver = adam
# learning_rate (required, str):
learning_rate = constant
# learning_rate_init (required, float):
learning_rate_init = 0.001
# alpha (required, float): (Original note: regularization default is better than higher values.)
alpha = 0.0001
# max_iter: (original value is 1000)
max_iter = 100
# early_stopping (required, bool):
early_stopping = False
# verbose (required, int): set verbose=1 for tuning feedforward neural network
verbose = 0


[SVM]
# C (required, float):
C = 10
# gamma (required, float):
gamma = 0.5
# probability (required, bool):
probability = True
# verbose (required, int): (Change back to 0 when done debugging)
verbose = 0
# n_jobs: n_jobs=-1: all cores being used, set to -2 for all cores but one.
n_jobs = -2


[UMAP]
# n_neighbors (required, int): TODO
n_neighbors = 100
# n_components (required, int): TODO
n_components = 3
# min_dist: small value
min_dist = 0.0


[TSNE]
# early_exaggeration (float, required):
early_exaggeration = 16
# n_components: 3 is good, 2 will not create unique pockets, 4 will screw GMM up (curse of dimensionality)
n_components = 3
# n_iter (): 250 is the min...previous n_iter was set to 1,000
n_iter = 250
# n_jobs: n_jobs=-1: all cores being used, set to -2 for all cores but one.
n_jobs = -2
# theta (float, required):
theta = 0.5
# verbose: (original note: verbose=2 shows check points)
verbose = 0










